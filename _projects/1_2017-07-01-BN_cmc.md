---
title: "Why batch normalization works so well?"
collection: projects
permalink: /projects/2017-01-12-ACIIDS17_cmc
date: 2017-07-01
venue: 'Final project, NTU, 2017.'
paperurl: 'http://nothinghard.github.io/files/ACIIDS17_cmc.pdf'
paperimg: '../images/crime_all.png'
---

## Abstract
Batch normalization (BN) has been proposed in 2015, and immediately attracts a lot of attentions from researchers and industry practitioners. Nowaday BN is regarded as the necessary component in many well-known neural network architectures to speed up network training phrase and achieve model performance. This project aims at validating the effectiveness of BN claimed by the authors, and also discovering evidences to show that why batch normalization works so well.